{
  "project_name": "Content Verification System",
  "last_updated": "2024-07-16T04:39:06.560962",
  "files": [
    {
      "filename": "main.py",
      "type": "Python Script",
      "last_modified": "2024-07-16T04:39:06.560986",
      "content_preview": "import inquirer\nfrom state_machine import StateMachine\nfrom queue_manager import QueueManager\nfrom l...",
      "description": "This main.py file serves as the entry point for the Content Verification System. It implements an asynchronous main menu using the inquirer library, allowing users to interact with various system functionalities. The script integrates key components such as the state machine, queue manager, launch check, scraper, settings manager, and database operations. It includes functions for running the main program loop, manual scraping, database searching and viewing, and debug operations like database population from Plex, purging, and creating a wanted database. The file demonstrates the system's modular structure, integrating with content checkers, parsers, processors, caches, verifiers, and scrapers. It provides a user-friendly interface for system interaction and showcases the project's capabilities in content verification, processing, and management."
    },
    {
      "filename": "state_machine.py",
      "type": "Python Class",
      "last_modified": "2024-07-14T21:23:52.137958",
      "content_preview": " class StateMachine:     def __init__(self):         self.state = \"initial\"      def transition(self...",
      "description": "This file defines the StateMachine class, which is a core component of the Content Verification System. It manages the system's current state and provides a method for transitioning between states. The class is currently minimal, with a basic initialization setting the initial state and a transition method that needs to be implemented with specific state transition logic. This class likely plays a crucial role in controlling the workflow of the content verification process, potentially managing states such as content fetching, verification, processing, and result handling."
    },
    {
      "filename": "database.py",
      "type": "Python Module",
      "last_modified": "2024-07-15T19:08:09.744077",
      "content_preview": "import sqlite3\nimport logging\nfrom tqdm import tqdm\nfrom datetime import datetime\n\nlogging.basicConf...",
      "description": "This database.py file is a core component of the Content Verification System, handling all database operations using SQLite. It provides functions for database creation, connection management, and CRUD operations for collected movies and TV episodes. The module includes functions to create tables, add collected items in batches, search, and retrieve data. It uses SQLite for data storage, with tables for collected_movies and collected_episodes, each containing relevant fields like imdb_id, tmdb_id, title, and year. The module implements logging for tracking operations and errors, and uses tqdm for progress bars during batch operations. It's designed to work closely with other components of the system, particularly the plex_integration.py module, to maintain a record of verified and collected content. The file's location in the project root indicates its importance and accessibility to other modules throughout the project."
    },
    {
      "filename": "queue_manager.py",
      "type": "Python Class",
      "last_modified": "2024-07-14T21:34:03.322498",
      "content_preview": "from rich.live import Live\nfrom rich.table import Table\nfrom rich.panel import Panel\nfrom rich.layou...",
      "description": "This file defines the QueueManager class, a critical component of the Content Verification System. It manages multiple queues for different stages of the content processing pipeline (scrape, process, cache, verify) and tracks item states. The class provides methods for adding items to queues, processing queues asynchronously, updating item states, and displaying queue and state status using the rich library for a live, interactive console output. It integrates with the project's asynchronous architecture and plays a crucial role in organizing, tracking, and visualizing the flow of content through the verification system. The use of rich tables and layouts suggests a sophisticated CLI interface for monitoring system status in real-time."
    },
    {
      "filename": "rate_limiter.py",
      "type": "Python Class",
      "last_modified": "2024-07-14T21:23:52.138958",
      "content_preview": " import asyncio  class RateLimiter:     def __init__(self, rate_limit):         self.rate_limit = ra...",
      "description": "This file defines the RateLimiter class, which implements a token bucket algorithm for rate limiting in the Content Verification System. It's designed to work asynchronously, integrating with the project's asyncio-based architecture. The RateLimiter helps manage and control the rate of operations, likely for API calls or content processing, ensuring the system doesn't exceed specified limits. This component is crucial for maintaining system performance and adhering to external service usage policies."
    },
    {
      "filename": "launch_check.py",
      "type": "Python Module",
      "last_modified": "2024-07-15T18:45:05.012952",
      "content_preview": "from database import verify_database\n\ndef perform_launch_check():\n    # Perform initial safety check...",
      "description": "This launch_check.py module is a crucial component of the Content Verification System, responsible for performing initial safety checks and setup procedures when the system starts. It contains a function perform_launch_check() that verifies and initializes the database using the verify_database function imported from the database module. The function also includes placeholders for loading current items, checking for new requests from external content producers, and updating the database with new items. This module plays a vital role in ensuring the system is properly initialized before beginning its main operations, integrating closely with the database module and potentially other components like content checkers and queue management. Its placement in the project root directory indicates its importance in the system startup process."
    },
    {
      "filename": "content_checkers/mdb_list_checker.py",
      "type": "Python Module",
      "last_modified": "2024-07-14T21:23:52.138958",
      "content_preview": " async def check_mdb_list_requests():     # Mock function to simulate fetching requests from MDB Lis...",
      "description": "This module is part of the Content Verification System's content checking functionality. It contains an asynchronous function check_mdb_list_requests() which is designed to fetch requests from the MDB List. Currently, it's a mock function, likely serving as a placeholder for future implementation. This module is crucial for integrating MDB List checks into the content verification process, potentially used to validate or filter content against a specific database or list of criteria."
    },
    {
      "filename": "content_checkers/overseer_checker.py",
      "type": "Python Module",
      "last_modified": "2024-07-15T21:23:18.108942",
      "content_preview": "from settings import get_setting\nimport logging\nimport requests\n\nlogging.basicConfig(level=logging.I...",
      "description": "This overseer_checker.py module is a key component of the content_checkers package in the Content Verification System. It provides functionality to interface with the Overseerr API, fetching content requests and unavailable content information. The module includes two main functions: check_overseer_requests() for checking general Overseerr requests, and get_unavailable_content() which specifically retrieves a list of unavailable content items from Overseerr. It utilizes the project's settings module to retrieve Overseerr URL and API key, demonstrating integration with the system's configuration management. The module implements error handling and logging for robustness. It plays a crucial role in identifying user-requested and unavailable content that needs verification or processing, forming an essential part of the content verification workflow. The module's location in the content_checkers directory indicates its specific role in checking external content request sources within the larger content verification and processing pipeline."
    },
    {
      "filename": "content_checkers/__init__.py",
      "type": "Python Module",
      "last_modified": "2024-07-14T21:23:52.138958",
      "content_preview": "",
      "description": "This is the __init__.py file for the content_checkers package in the Content Verification System. It likely serves to make the content_checkers directory a Python package, allowing the mdb_list_checker and overseer_checker modules to be imported elsewhere in the project. This file may also include any package-level initializations or imports necessary for the content checking functionality."
    },
    {
      "filename": "parser/parse_results.py",
      "type": "Python Module",
      "last_modified": "2024-07-14T21:23:52.138958",
      "content_preview": " async def parse_scraped_results(scraped_data):     # Mock function to simulate parsing scraped resu...",
      "description": "This module is part of the parser package in the Content Verification System. It contains an asynchronous function parse_scraped_results() which is designed to parse the results obtained from web scraping operations. Currently, it's a mock function, serving as a placeholder for future implementation. This module plays a crucial role in processing and structuring the raw data obtained from web scraping, preparing it for further verification and analysis in the content verification pipeline. It likely interfaces with the scraper module and feeds into the processor or verifier components of the system."
    },
    {
      "filename": "parser/__init__.py",
      "type": "Python Module",
      "last_modified": "2024-07-14T21:23:52.138958",
      "content_preview": "",
      "description": "This is the __init__.py file for the parser package in the Content Verification System. It likely serves to make the parser directory a Python package, allowing the parse_results module to be imported elsewhere in the project. This file may also include any package-level initializations or imports necessary for the parsing functionality, which is crucial for processing scraped data before further verification and analysis in the content verification pipeline."
    },
    {
      "filename": "processor/process_request.py",
      "type": "Python Module",
      "last_modified": "2024-07-14T21:37:17.565787",
      "content_preview": "from settings import get_setting\n\nasync def process_debrid_request(request_data):\n    real_debrid_ap...",
      "description": "This module is part of the processor package in the Content Verification System. It contains an asynchronous function process_debrid_request() which is designed to process debrid requests using the Real-Debrid API. The function retrieves the Real-Debrid API key from the settings module, demonstrating integration with the project's configuration management. Currently, it's a placeholder with print statements for demonstration, but it's designed to be implemented with actual processing logic in the future. This module plays a crucial role in handling specific types of content requests related to debrid services within the content verification and processing pipeline. It interfaces with other components of the system, such as the settings module, and is part of the larger asynchronous architecture of the system. The use of Real-Debrid suggests that this module is involved in processing and potentially resolving premium file hosting links as part of the content verification process."
    },
    {
      "filename": "processor/__init__.py",
      "type": "Python Module",
      "last_modified": "2024-07-14T21:23:52.138958",
      "content_preview": "",
      "description": "This is the __init__.py file for the processor package in the Content Verification System. It serves to make the processor directory a Python package, allowing the process_request module to be imported elsewhere in the project. This file may include package-level initializations or imports necessary for the processing functionality, which is crucial for handling specific types of content requests, such as debrid requests, within the content verification and processing pipeline."
    },
    {
      "filename": "cache/cache_content.py",
      "type": "Python Module",
      "last_modified": "2024-07-14T21:37:04.130644",
      "content_preview": "from settings import get_setting\n\nasync def cache_in_plex_library(content_data):\n    plex_url = get_...",
      "description": "This module is part of the cache package in the Content Verification System. It contains an asynchronous function cache_in_plex_library() which simulates caching content in the Plex library. The function uses settings from the settings module to retrieve Plex URL and token. It's currently a placeholder with print statements for demonstration, but it's designed to be implemented with actual caching logic in the future. This module plays a crucial role in the caching stage of the content verification process, potentially storing verified or processed content for later retrieval or use within a Plex media server environment. It integrates with the settings module and is part of the larger asynchronous architecture of the system."
    },
    {
      "filename": "cache/__init__.py",
      "type": "Python Module",
      "last_modified": "2024-07-14T21:23:52.138958",
      "content_preview": "",
      "description": "This is the __init__.py file for the cache package in the Content Verification System. It serves to make the cache directory a Python package, allowing the cache_content module to be imported elsewhere in the project. This file may include package-level initializations or imports necessary for the caching functionality, which is crucial for storing verified or processed content, potentially within a Plex media server environment, as part of the content verification and processing pipeline."
    },
    {
      "filename": "verifier/verify_item.py",
      "type": "Python Module",
      "last_modified": "2024-07-14T21:37:08.642011",
      "content_preview": "from settings import get_setting\n\nasync def verify_item_in_plex(item_id):\n    plex_url = get_setting...",
      "description": "This module is part of the verifier package in the Content Verification System. It contains an asynchronous function verify_item_in_plex() which is designed to verify the presence of an item in the Plex library. The function uses settings from the settings module to retrieve Plex URL and token. Currently, it's a placeholder with print statements for demonstration, but it's designed to be implemented with actual verification logic in the future. This module plays a crucial role in the verification stage of the content processing pipeline, confirming the presence of processed or cached content within a Plex media server environment. It integrates with the settings module and is part of the larger asynchronous architecture of the system, potentially interfacing with the queue manager and state machine to manage the flow of content through the verification stage."
    },
    {
      "filename": "verifier/__init__.py",
      "type": "Python Module",
      "last_modified": "2024-07-14T21:23:52.138958",
      "content_preview": "",
      "description": "This is the __init__.py file for the verifier package in the Content Verification System. It serves to make the verifier directory a Python package, allowing the verify_item module to be imported elsewhere in the project. This file may include package-level initializations or imports necessary for the verification functionality, which is crucial for confirming the presence and validity of processed or cached content, potentially within a Plex media server environment, as part of the content verification and processing pipeline."
    },
    {
      "filename": "scraper/scraper.py",
      "type": "Python Module",
      "last_modified": "2024-07-16T04:35:16.862754",
      "content_preview": "import asyncio\nfrom .zilean import scrape_zilean\nfrom .torrentio import scrape_torrentio\n\nasync def ...",
      "description": "This scraper.py module is a core component of the Content Verification System's scraper package. It implements an asynchronous scrape_url function that coordinates multiple scraping operations. The module integrates two specific scrapers: Zilean and Torrentio, using asyncio to run them concurrently. It aggregates results from these scrapers into a single dictionary, providing a unified interface for content scraping across different sources. This design allows for easy expansion to include additional scrapers in the future. The module plays a crucial role in the initial data gathering stage of the content verification process, fetching raw content data that will be further processed and verified by other system components."
    },
    {
      "filename": "scraper/__init__.py",
      "type": "Python Module",
      "last_modified": "2024-07-14T21:23:52.138958",
      "content_preview": "",
      "description": "This is the __init__.py file for the scraper package in the Content Verification System. It serves to make the scraper directory a Python package, allowing the scraper module to be imported elsewhere in the project. This file may include package-level initializations or imports necessary for the scraping functionality, which is crucial for fetching raw content from specified URLs as part of the initial data gathering stage in the content verification and processing pipeline."
    },
    {
      "filename": "drd.json",
      "type": "json",
      "last_modified": "2024-07-15T21:21:51.050589",
      "content_preview": "{\n  \"project_name\": \"Content Verification System\",\n  \"last_updated\": \"2024-07-15T21:21:51.049725\",\n ...",
      "description": ""
    },
    {
      "filename": "settings.py",
      "type": "Python Module",
      "last_modified": "2024-07-15T00:58:37.321961",
      "content_preview": "import configparser\nimport os\n\nCONFIG_FILE = 'config.ini'\n\ndef load_config():\n    config = configpar...",
      "description": "This settings.py file is a crucial component of the Content Verification System, responsible for managing configuration settings. It provides functions to load, save, get, and set configuration values using a config.ini file. The module includes an interactive edit_settings() function that allows users to update settings for Plex, Overseerr, Real-Debrid, Trakt, and TMDB services. This file plays a vital role in maintaining the system's configuration, ensuring that various components can access necessary API keys, URLs, and other settings. It integrates well with the modular structure of the project and supports the configuration needs of different services used in the content verification and processing pipeline. The file is located in the project root directory, indicating its importance and accessibility to other modules throughout the project."
    },
    {
      "filename": "plex_integration.py",
      "type": "Python Module",
      "last_modified": "2024-07-15T19:08:17.663728",
      "content_preview": "from plexapi.server import PlexServer\nimport logging\nfrom tqdm import tqdm\n\nlogging.basicConfig(leve...",
      "description": "This plex_integration.py module is a crucial component of the Content Verification System, responsible for integrating with Plex media server and collecting content information. It uses the PlexAPI library to connect to a Plex server, retrieve movie and TV show data, including IMDB and TMDB IDs, titles, years, and episode details. The module includes functions for collecting content from Plex (collect_content_from_plex) and populating the database with this content (populate_db_from_plex). It implements error handling, logging, and uses tqdm for progress bars. This file plays a vital role in gathering existing media information from a Plex server, supporting the project's content verification and management capabilities. It integrates with the database module for adding collected movies and episodes to the system's content database. The file's location in the project root indicates its importance in the overall system architecture and its role in initializing the system with current media library information."
    },
    {
      "filename": "scraper/zilean.py",
      "type": "Python Module",
      "last_modified": "2024-07-16T04:35:21.375444",
      "content_preview": "import aiohttp\n\nasync def scrape_zilean(url):\n    # This is a placeholder implementation. Replace wi...",
      "description": "This zilean.py file is part of the scraper package in the Content Verification System. It defines an asynchronous function scrape_zilean that performs web scraping on a given URL, specifically targeting the Zilean service. The function uses aiohttp for asynchronous HTTP requests. Currently, it contains a placeholder implementation that simulates scraping results, returning a list of dictionaries with sample torrent data including name, size, seeders, and leechers. This module is designed to be integrated with the main scraper.py file, which coordinates multiple scraping operations. The placeholder nature suggests it's prepared for future implementation of actual Zilean-specific scraping logic. Its location in the scraper directory indicates its role in the initial data gathering stage of the content verification process."
    },
    {
      "filename": "scraper/torrentio.py",
      "type": "Python Module",
      "last_modified": "2024-07-16T04:38:16.679948",
      "content_preview": "import aiohttp\nimport json\nimport re\nfrom types import SimpleNamespace\n\nDEFAULT_OPTS = \"https://torr...",
      "description": "This torrentio.py file is a crucial component of the scraper package in the Content Verification System. It implements an asynchronous function scrape_torrentio that performs web scraping specifically for the Torrentio service. The module includes functions for querying the Cinemeta API to obtain IMDB IDs, constructing Torrentio-specific URLs, fetching data asynchronously using aiohttp, and parsing the results. It handles both movies and TV shows, extracting information such as title, size, seeders, and magnet links from the Torrentio streams. The file demonstrates integration with the project's asynchronous architecture and provides a specialized scraping capability that complements other scrapers like zilean.py. Its location in the scraper directory and its detailed implementation indicate its significant role in the initial data gathering stage of the content verification process, contributing to the system's ability to collect and process torrent information from multiple sources."
    }
  ],
  "dev_server": {
    "start_command": "python main.py",
    "framework": "Custom",
    "language": "Python"
  },
  "description": "This project appears to be a content verification and processing system. It likely involves scraping content, checking it against various databases or lists (such as MDB list and Overseer), processing requests, managing a queue, implementing rate limiting, and verifying items. The system seems to use a state machine for workflow control and includes caching mechanisms. It's designed with a modular structure, separating concerns into different components like content checking, parsing, processing, caching, verification, and scraping."
}